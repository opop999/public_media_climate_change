---
title: "Topic modeling"
---

## Load necessary packages
```{r include=FALSE}
# Package names
packages <- c("dplyr", "parallel", "stringr", "text2map", "data.table", "dtplyr", "text2vec", "LDAvis", "jsonlite", "tidyr", "DT", "ggplot2")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

stop_words_cs <- c(fromJSON("data/irene_stopwords.json"),
                   fromJSON("data/stopwords_cs.json")) %>%
                   unique()

```


```{r}
udpipe_chunks <- list.files(path = "../../2.data_transformations/data/udpipe_processed/", pattern = "*.rds", full.names = TRUE)

process_df <- function(i) {
  
  readRDS(i) %>% 
    lazy_dt() %>% 
    filter(upos %in% c("NOUN") & nchar(lemma) > 1) %>% # filter one letter words    
    transmute(doc_id, lemma = tolower(str_replace_na(lemma, replacement = ""))) %>% 
    group_by(doc_id) %>%
    summarize(text = str_squish(str_c(lemma, collapse = " "))) %>%
    ungroup() %>% 
    as_tibble()

}

combined_df <- mclapply(udpipe_chunks, process_df, mc.cores = detectCores() - 1) %>% bind_rows()


# combined_df <- combined_df %>% 
#   group_by(doc_id) %>%
#   summarize(text = str_squish(str_c(lemma, collapse = " "))) %>%
#   ungroup() %>% 
#   as_tibble()

```

```{r}

dtm_udpipe <- dtm_builder(data = combined_df, text = "text", doc_id = "doc_id")

# dtm_stats(dtm_udpipe)

dtm_less_sparse <- dtm_stopper(dtm_udpipe,
                               stop_list = stop_words_cs,
                               stop_hapax = TRUE,
                               stop_null = TRUE,
                               stop_docprop = c(0.01, 0.2),
                               # stop_docfreq = c(floor(nrow(dtm_udpipe) * 0.01), ceiling(nrow(dtm_udpipe) * 0.5))
                               )

# Check for presence of climate related items
colnames(dtm_less_sparse)[grep(x = colnames(dtm_less_sparse), pattern = "klim.*")]


dtm_stats(dtm_less_sparse)

saveRDS(dtm_less_sparse, "data/dtm_less_sparse_adj.rds")

```

```{r}
lda_model <- LDA$new(n_topics = 20L)

set.seed(3859L)
doc_topic_distribution <- lda_model$fit_transform(
    x = dtm_less_sparse,
    n_iter = 1000,
    convergence_tol = 0.001,
    n_check_convergence = 10
  )

saveRDS(doc_topic_distribution, "data/doc_topic_distribution.rds")

saveRDS(lda_model, "data/lda_model.rds")

```


```{r}
# The lower perplexity the better. 

perplexity(dtm_less_sparse, topic_word_distribution = lda_model$topic_word_distribution, doc_topic_distribution = doc_topic_distribution)

# Proportion of topics in the corpus vizualization

doc_topic_distribution %>%
      colMeans() %>% 
      setNames(paste0("topic_", 1:length(.))) %>% 
      as_tibble(rownames = "topic") %>%
      mutate(topic = reorder(as.factor(topic), desc(value))) %>% 
      ggplot(aes(x = topic, y = value)) + 
        geom_bar(stat = "identity")

lda_model$get_top_words(lambda = 1) %>% as.data.frame() %>% setNames(paste0("topic_", 1:ncol(.))) %>% datatable() 

lda_model$plot(out.dir = "plot", as.gist = TRUE)

                           
serVis("plot/lda.json", as.gist = TRUE, filename = "topic_20")

gist_create(file.path(out.dir, list.files(out.dir))), filename = "topic_20"))


barplot(
  doc_topic_distribution[1,],
  xlab = "topic",
  ylab = "proportion",
  ylim = c(0, 1),
  names.arg = 1:ncol(doc_topic_distribution)
)


# Calculation of metrics for k topics
# library(ldatuning)
# 
# result <- FindTopicsNumber(dtm_less_sparse,
#                            mc.cores = parallel::detectCores() - 1)
# FindTopicsNumber_plot(result)

```

